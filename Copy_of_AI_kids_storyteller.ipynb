{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBshbqTjTCZOVJWvzdeM3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alapan-Manna/AICTE_B7/blob/main/Copy_of_AI_kids_storyteller.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDgvLamg7sQR",
        "outputId": "732e683f-7976-4d90-a261-7c097022ad15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GEMINI_API_KEY=AIzaSyDJSpRY2UWCp5u7QtQXliw1ryJNSCfyaAk\n"
          ]
        }
      ],
      "source": [
        "%env GEMINI_API_KEY=AIzaSyDJSpRY2UWCp5u7QtQXliw1ryJNSCfyaAk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers pillow google-generativeai"
      ],
      "metadata": {
        "id": "vrpCDAUE734b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "client=genai.Client()"
      ],
      "metadata": {
        "id": "YzITeIF479xI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set your Gemini API key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "  client=genai.Client()\n",
        "  MODEL=\"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "rfDjmMA48FdG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=input(\"Enter your Story prompt and press enter:\\n\")\n",
        "if prompt.strip()==\"\":\n",
        "  print(\"No prompt entered , Exiting.\")\n",
        "else:\n",
        "  print(f\"Generating story for prompt: {prompt}\")\n",
        "  print(\"It may take few seconds\")\n",
        "  try:\n",
        "    resp=client.models.generate_content(model=MODEL,contents=[prompt])\n",
        "    print(\"\\n----Generated Story----\\n\")\n",
        "    print(resp.text)\n",
        "  except Exception as e:\n",
        "    print(f\"Error occurred while generating story: {e}\")"
      ],
      "metadata": {
        "id": "Qg5yxccj8OEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers pillow google-generativeai timm"
      ],
      "metadata": {
        "id": "-rQDg6yb8gyh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "from google import genai\n",
        "import os\n",
        "import io"
      ],
      "metadata": {
        "id": "WysR_Lsl8oy0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GEMINI_API_KEY\" not in os.environ:\n",
        "  print(\"Please set your Gemini API key in the environment variable GEMINI_API_KEY\")\n",
        "else:\n",
        "  client=genai.Client()\n",
        "  MODEL=\"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "7F83Aycz8uOn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor=BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model=BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
      ],
      "metadata": {
        "id": "X9LnnTDl857L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  image=Image.open(fn).convert('RGB')\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "WiO_ss629Bcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=processor(images=image,return_tensors='pt')\n",
        "out=model.generate(**inputs)\n",
        "\n",
        "caption=processor.decode(out[0],\n",
        "skip_special_tokens=True)\n",
        "\n",
        "print(\"Caption generated by BLIP: \")\n",
        "print(caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIs-4dIE9QNq",
        "outputId": "21cf3129-180a-4cbe-9ed4-7207df8dcc7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caption generated by BLIP: \n",
            "a close up of a single flower in a field of grass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story_prompt=(f\"Write a Short story(around 500-700 words) based on this scene description: {caption}\")\n",
        "print(story_prompt)\n",
        "\n",
        "print(\"Sending this to Gemini. \\n\")\n",
        "\n",
        "response = client.models.generate_content(model=MODEL, contents=story_prompt)\n",
        "story=response.text\n",
        "print(\"\\n----Generated Story----\\n\")\n",
        "print(story)\n"
      ],
      "metadata": {
        "id": "rSzDWscK9q94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"generated_story.txt\",\"w\")as f:\n",
        "  f.write(story)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"generated_story.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "brjCZIXO_Dn-",
        "outputId": "f7e6903d-b2c1-4023-a26c-d90bce8a9c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b533237f-75e8-4332-96ed-8e47aba3adf8\", \"generated_story.txt\", 3600)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipywidgets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnUurntPAKoF",
        "outputId": "c2c67c26-05d4-483f-8850-f040b3610702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.4/1.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "uploaded=files.upload()\n",
        "images=[]\n",
        "image_names=[]\n",
        "\n",
        "for name,file in uploaded.items():\n",
        "  image=Image.open(io.BytesIO(file)).convert('RGB')\n",
        "  image_names.append(name)\n",
        "  images.append(image)\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "YYQfdZ7FAegs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "captions = []\n",
        "for img in images:\n",
        "    inputs = processor(images=img, return_tensors='pt')\n",
        "    out = blip_model.generate(**inputs, max_new_tokens=30)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    captions.append(caption)\n",
        "\n",
        "print(\"Generated Captions:\")\n",
        "for i, caption in enumerate(captions):\n",
        "    print(f\"{image_names[i]}: {caption}\")"
      ],
      "metadata": {
        "id": "QCqXx5GNaUFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "tone_dropdown = widgets.Dropdown(\n",
        "    options=[\"whimsical\", \"adventurous\", \"suspenseful\", \"romantic\", \"sci-fi\", \"mystery\"],\n",
        "    value='sci-fi',\n",
        "    description='Tone:'\n",
        ")\n",
        "\n",
        "length_dropdown = widgets.Dropdown(\n",
        "    options=[\"Short (100-200 words)\", \"Medium (200-400 words)\", \"Long (500-700 words)\"],\n",
        "    value=\"Medium (200-400 words)\",\n",
        "    description='Length:'\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate Story\")\n",
        "output_box = widgets.Output()\n",
        "\n",
        "display(tone_dropdown, length_dropdown, generate_button, output_box)"
      ],
      "metadata": {
        "id": "4QjtRRM3c1Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_generate_clicked(b):\n",
        "    print(\"Working\")\n",
        "    output_box.clear_output()\n",
        "    with output_box:\n",
        "        clear_output()\n",
        "        tone = tone_dropdown.value\n",
        "        length_map = {\n",
        "            \"Short (100-200 words)\": \"100-200 words\",\n",
        "            \"Medium (200-400 words)\": \"200-400 words\",\n",
        "            \"Long (400-600 words)\": \"400-600 words\"\n",
        "        }\n",
        "        length = length_map[length_dropdown.value]\n",
        "        caption_prompt = \"\\n\".join([f\"- {c}\" for c in captions])\n",
        "        outline_prompt = (\n",
        "            f\"Using the following scene descriptions, create a 3-chapter story outline. \"\n",
        "            f\"Each chapter should have a title and a short summary.\\n\\n\"\n",
        "            f\"{caption_prompt}\\n\\nOutline:\"\n",
        "        )\n",
        "\n",
        "\n",
        "        try:\n",
        "    # Generate Outline\n",
        "             outline_response = client.models.generate_content(model=MODEL,contents=outline_prompt)\n",
        "\n",
        "             outline_text = outline_response.text\n",
        "             print(\"Story Outline:\\n\")\n",
        "             print(outline_text)\n",
        "\n",
        "             full_story = \"\"\n",
        "\n",
        "    # Generate 3 Chapters\n",
        "             for i in range(1, 4):\n",
        "                 chapter_prompt = (\n",
        "                     f\"Using the outline below, write Chapter {i} in a {tone} tone. \"\n",
        "                     f\"Make it {length}. Add vivid details, good pacing, and consistent characters.\\n\\n\"\n",
        "                     f\"{outline_text}\\n\\nChapter {i}:\"\n",
        "                 )\n",
        "\n",
        "                 chapter_response = client.models.generate_content(model=MODEL,contents=chapter_prompt)\n",
        "\n",
        "                 chapter_text = chapter_response.text\n",
        "                 print(f\"\\nChapter {i}:\\n\")\n",
        "                 print(chapter_text)\n",
        "\n",
        "                 full_story += f\"\\n\\nChapter {i}:\\n{chapter_text}\"\n",
        "\n",
        "    # Save story to file\n",
        "             with open(\"multi_image_story.txt\", \"w\") as f:\n",
        "                f.write(full_story)\n",
        "\n",
        "             print(\"\\nStory saved as multi_image_story.txt\")\n",
        "\n",
        "    # Download file (Google Colab)\n",
        "             from google.colab import files\n",
        "             files.download(\"multi_image_story.txt\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Error generating story:\", e)\n",
        "generate_button.on_click(on_generate_clicked)"
      ],
      "metadata": {
        "id": "URICYqtd0t65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gtts reportlab"
      ],
      "metadata": {
        "id": "61z0xrWeg8BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_text=\"\"\"\n",
        "**Chapter 1: The Digital Echo**\n",
        "\n",
        "*   **Summary:** Alex, a brilliant but reclusive audio forensic specialist, is immersed in their work. On a sprawling, multi-panel display, complex data visualizations and geographical maps scroll, but their focus is entirely on a dedicated monitor showcasing a perplexing **sound wave**. It's a fragment of audio from an anonymous client, a recording riddled with static and distortion, yet containing an almost imperceptible undercurrent that hints at something deeply significant. This cryptic sound wave is Alex's latest obsession, drawing them into an unsettling new mystery.\n",
        "\n",
        "**Chapter 2: Resonance and Revelation**\n",
        "\n",
        "*   **Summary:** Days blend into nights as Alex meticulously dissects the enigmatic sound wave. The main workstation, with its **large display**, is now a canvas of spectral analyses, waveform comparisons, and layered audio tracks, all meticulously scrutinized. Through painstaking digital archaeology, Alex isolates faint, almost imperceptible background noises ‚Äì a unique engine hum, a distant, specific environmental reverberation. This breakthrough narrows down the potential origin of the recording to a particular affluent area, revealing a hidden layer of intrigue that escalates the stakes of the case.\n",
        "\n",
        "**Chapter 3: The Crimson Clue**\n",
        "\n",
        "*   **Summary:** Armed with the decoded audio data and precise geographical markers, Alex tracks the source to a secluded, opulent estate on the outskirts of the city. Their heart pounds as they approach, the final pieces of the puzzle clicking into place. Parked conspicuously on the immaculate paved driveway, gleaming under the sunlight, is a magnificent **red and white Rolls Royce**. It's the very vehicle whose distinctive engine hum Alex had painstakingly identified in the sound wave, solidifying the link between the cold digital data and a very tangible, high-stakes reality. The confrontation, or the final revelation, is now imminent.\n",
        "\n",
        "Chapter 1:\n",
        "\n",
        "The cool hum of the bio-luminescent panels bathed Alex‚Äôs workspace in a soft, ethereal glow, reflecting off a meticulously organized chaos of discarded data chips and forgotten nutrient paste packets. Strewn across the room's main console, a sprawling array of ultra-HD displays rendered constellations of data visualizations, real-time geographical topographies, and cascading lines of algorithmic code. Yet, Alex, a figure as brilliant as they were reclusive, saw none of it. Their focus was laser-sharp, locked onto a single, dedicated holoscreen levitating above the console.\n",
        "\n",
        "On this central display, a singular, perplexing sound wave pulsated‚Äîa jagged, spectral ghost against a dark digital canvas. It was a mere fragment, anonymously uploaded, riddled with the white noise and distortion typical of a badly compressed recording from some remote corner of the grid. But beneath the static, an almost imperceptible undercurrent rippled. A faint harmonic, an unnatural cadence that defied simple corruption.\n",
        "\n",
        "Alex‚Äôs fingers danced across a haptic interface, zooming, scrubbing, applying filters with an almost surgical precision. Hours bled into each other, marked only by the shifting hues of the display and the faint scent of ozone. Most would dismiss it as digital detritus, a phantom echo of nothing. But Alex‚Äôs mind, a neural network of pattern recognition and forensic insight, knew better. This wasn't just noise; it was a veiled message, a whisper beneath the storm. A dangerous curiosity ignited in their eyes, drawing them deeper into the unsettling new mystery encoded within the digital echo.\n",
        "\n",
        "Chapter 2:\n",
        "\n",
        "Days bled into nights within the humming sanctum of Alex‚Äôs lab, the outside world a blur of forgotten meals and ignored notifications. The main workstation, a behemoth of integrated displays, pulsed with an ethereal blue light, transforming into a vast canvas of digital archaeology. Spectral analyses bloomed like alien flora across the largest monitor, each pixel a data point in a complex auditory ecosystem. Waveform comparisons scrolled in holographic readouts, stacked like geological strata, while layered audio tracks intertwined, revealing previously hidden patterns in the cacophony.\n",
        "\n",
        "Alex's fingers danced over a haptic interface, manipulating intricate filters and AI-driven amplification algorithms. Hour after hour, they chiseled away at the static, sifting through the digital detritus until a faint ghost of a signal emerged. It was less a sound and more a *signature*. First, a low, resonant thrum ‚Äì a unique engine hum. Not just any engine, but one with a distinct sub-harmonic signature, indicative of advanced propulsion and bespoke luxury engineering. A quick cross-reference with global vehicular databases pinged several high-end, customized models.\n",
        "\n",
        "Then came the environmental reverberation. A subtle echo, a specific acoustic fingerprint of high ceilings and polished, reflective surfaces, juxtaposed with the faint, filtered hum of a distant, manicured cityscape. Alex fed the data into a geo-acoustic profiling suite. The algorithms whirred, cross-referencing acoustic signatures with architectural databases and topographical maps. A cluster of probability zones illuminated on an overlay, all converging on a tightly guarded, affluent district nestled in the city's verdant outskirts ‚Äì an area synonymous with old money and impenetrable estates. The revelation sent a shiver down Alex's spine. The anonymous client, the cryptic sound wave, now led directly to a world of privilege and hidden secrets, escalating the stakes beyond mere forensics. The quiet hum of the lab seemed to amplify, mirroring the intrigue that now vibrated through the core of Alex's latest obsession.\n",
        "\n",
        "Chapter 3:\n",
        "\n",
        "With the geo-coordinates locked and the spectral analysis irrefutable, Alex felt the familiar high of a puzzle solved, quickly subsumed by a potent surge of adrenaline. The sterile glow of the lab dissolved into the cool, pre-dusk air as their vehicle navigated the city‚Äôs upper echelons, the urban grid giving way to manicured, private arteries. Automated gates, their subtle energy fields shimmering almost invisibly, hissed open to reveal an estate that practically hummed with an almost offensive level of opulence.\n",
        "\n",
        "It was a fortress of polished granite and integrated smart-gardens, bioluminescent flora casting a soft, alien glow against the encroaching twilight. Alex‚Äôs internal chronometer registered an escalating heart rate, not just from the approach, but from the chilling certainty of their data now solidifying into a tangible, high-stakes reality. And then, there it was. Parked with brazen confidence on a paved driveway that gleamed like polished obsidian, stood a vehicle of exquisite, almost anachronistic beauty. A magnificent **red and white Rolls Royce**, its polished chrome accents catching the last slivers of sunlight like scattered diamonds.\n",
        "\n",
        "Every line, every curve, every flawless panel screamed a specific kind of old-world luxury, a silent testament to the vast wealth insulating this place. Alex‚Äôs breath caught in their throat. This was no digital phantom, no whisper on a waveform. This was the source, undeniably, unequivocally. The distinct, almost feline engine hum, painstakingly isolated and reconstructed from layers of static, now played back in Alex‚Äôs mind‚Äôs ear, perfectly matching the vehicle's unique sonic signature. The cold digital data from the lab had found its living embodiment, a crimson clue waiting in audacious plain sight. The final confrontation was not just imminent; it was parked directly in front of them, a silent, gleaming challenge under the gathering darkness.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-WLHhPpChwa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "\n",
        "def export_pdf(text,filename=\"story.pdf\"):\n",
        "  c=canvas.Canvas(filename,pagesize=letter)\n",
        "  width, height=letter\n",
        "  text_object=c.beginText(40, height-40)\n",
        "  text_object.setFont(\"Helvetica\",12)\n",
        "\n",
        "  for line in text.split('\\n'):\n",
        "       for subline in [line[i:i+90] for i in range(0,len(line),90)]:\n",
        "          text_object.textLine(subline)\n",
        "  c.drawText(text_object)\n",
        "  c.save()\n",
        "export_pdf(story_text)\n",
        "from google.colab import files\n",
        "files.download(\"story.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "N_lsyI4Ji0kR",
        "outputId": "e401f14f-936e-48ef-b4d3-e484209b8461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_25a82f24-b4ff-4db7-a324-2727678cd44f\", \"story.pdf\", 5854)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "voices = {\n",
        "    \"Default English\": {\"lang\": \"en\", \"tld\": \"com\", \"slow\": False},\n",
        "    \"British Accent\": {\"lang\": \"en\", \"tld\": \"co.uk\", \"slow\": False},\n",
        "    \"Australian Accent\": {\"lang\": \"en\", \"tld\": \"com.au\", \"slow\": False},\n",
        "    \"Indian Accent\": {\"lang\": \"en\", \"tld\": \"co.in\", \"slow\": False},\n",
        "    \"Slow Reading\": {\"lang\": \"en\", \"tld\": \"com\", \"slow\": True}\n",
        " }\n",
        "\n",
        "for label,options in voices.items():\n",
        "    print(f\"Generating audio for {label}...\")\n",
        "    tts = gTTS(text=story_text, lang=options[\"lang\"], tld=options.get(\"tld\", \"com\"), slow=options.get(\"slow\",False))\n",
        "    filename = f\"{label.replace(' ', '_').lower()}.mp3\"\n",
        "    tts.save(filename)\n",
        "    display(Audio(filename=filename, autoplay=False))\n",
        "    files.download(filename)"
      ],
      "metadata": {
        "id": "LVeBQaK66bIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_streamlit_story.py\n",
        "import streamlit as st #web app framework\n",
        "from PIL import Image\n",
        "import io, requests, os\n",
        "import textwrap\n",
        "from gtts import gTTS  #translate text to speech\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.utils import ImageReader\n",
        "from pyngrok import ngrok\n",
        "import tempfile\n",
        "import google.generativeai as genai\n",
        "import torch\n",
        "\n",
        "#Authencation\n",
        "NGROK_AUTH_TOKEN = \"32p3bRt5N7Yn4CLlwyZJk5HIe7c_xsX6L2urkk97RwmDLkRM\"\n",
        "BACKGROUND_IMAGE_URL = \"https://img.goodfon.com/wallpaper/big/1/71/mclaren-speedtail-mclaren-speedtail-4.webp\"\n",
        "GEMINI_API_KEY = \"AIzaSyDJSpRY2UWCp5u7QtQXliw1ryJNSCfyaAk\"\n",
        "\n",
        "#StreamLit Page Setup/Style\n",
        "st.set_page_config(page_title=\"StoryTeller\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp {{\n",
        "        background-image: url(\"{BACKGROUND_IMAGE_URL}\");\n",
        "        background-size: cover;\n",
        "        background-attachment: fixed;\n",
        "    }}\n",
        "    section[data-testid=\"stSidebar\"] {{\n",
        "        background: rgba(0,0,0,0.3);\n",
        "        backdrop-filter: blur(10px);\n",
        "        border-radius: 12px;\n",
        "        padding: 10px;\n",
        "    }}\n",
        "    div[data-testid=\"stFileUploader\"] {{\n",
        "        background: rgba(255,255,255,0.2);\n",
        "        border-radius: 10px;\n",
        "        padding: 10px;\n",
        "    }}\n",
        "    html, body, h1, h2, h3, h4, h5, h6, p, div, span, label, li, input, textarea {{\n",
        "        color: #93A8AC !important;\n",
        "    }}\n",
        "    .stButton>button, .stDownloadButton>button {{\n",
        "        color: #93A8AC !important;\n",
        "        border-color: #93A8AC;\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "\n",
        "st.title(\"Multi-Image AI StoryTeller\")\n",
        "st.markdown(\"Upload images ‚Üí Generate story ‚Üí Export as PDF & MP3\")\n",
        "\n",
        "with st.sidebar:\n",
        "    tone = st.selectbox(\"Tone\", [\"Adventurous\", \"Whimsical\", \"Romantic\", \"Mysterious\", \"Humorous\", \"Calm\"])\n",
        "    length_label = st.selectbox(\"Length\", [\"Short (200-300 words)\", \"Medium (300-600 words)\", \"Long (600-1000 words)\"])\n",
        "    start_ngrok = st.checkbox(\"Start ngrok tunnel\")\n",
        "    if start_ngrok:\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "        url = ngrok.connect(8501)\n",
        "        st.success(f\"Public URL: {url}\")\n",
        "\n",
        "\n",
        "uploaded_images = st.file_uploader(\"Upload multiple images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "#Caption model\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return processor, model\n",
        "\n",
        "processor, blip_model = load_models()\n",
        "\n",
        "#config gemini\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "@st.cache_resource\n",
        "def load_gemini_model():\n",
        "    return genai.GenerativeModel(model_name=\"models/gemini-2.5-flash\")\n",
        "\n",
        "gemini_model = load_gemini_model()\n",
        "\n",
        "#captioning the images\n",
        "def get_captions(images):\n",
        "    captions = []\n",
        "    for img in images:\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(blip_model.device)\n",
        "        out = blip_model.generate(**inputs)\n",
        "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "        captions.append(caption)\n",
        "    return captions\n",
        "\n",
        "\n",
        "def generate_story(captions, tone, length_label):\n",
        "    length_map = {\n",
        "        \"Short\": (200, 300, 1000),\n",
        "        \"Medium\": (300, 600, 1500),\n",
        "        \"Long\": (600, 1000, 1900)\n",
        "    }\n",
        "    min_words, max_words, max_tokens = length_map.get(length_label, (1000, 1500, 1900))\n",
        "\n",
        "    prompt = (\n",
        "    f\"You are a creative writer. Write a {tone.lower()} story based on the following image captions:\\n\\n\"\n",
        "    + \"\\n\".join([f\"- {cap}\" for cap in captions])\n",
        "    + f\"\\n\\nThe story should be vivid, engaging, and emotionally rich, with a coherent beginning, middle, and end.\"\n",
        "    + f\"\\nMake it 700 words more than {max_words} words long.\"\n",
        ")\n",
        "\n",
        "\n",
        "    try:\n",
        "        response = gemini_model.generate_content(\n",
        "            contents=prompt,\n",
        "            generation_config=genai.GenerationConfig(\n",
        "                temperature=0.9,\n",
        "                top_p=0.95,\n",
        "                max_output_tokens=max_tokens\n",
        "            )\n",
        "        )\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error generating story: {e}\"\n",
        "\n",
        "#Pdf generation\n",
        "def create_pdf(story_text, images):\n",
        "    buffer = io.BytesIO()\n",
        "    c = canvas.Canvas(buffer, pagesize=A4)\n",
        "    w, h = A4\n",
        "\n",
        "    try:\n",
        "        bg_img = Image.open(requests.get(BACKGROUND_IMAGE_URL, stream=True).raw).convert(\"RGB\")\n",
        "        bg = ImageReader(bg_img)\n",
        "        c.drawImage(bg, 0, 0, width=w, height=h)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    c.setFont(\"Helvetica-Bold\", 16)\n",
        "    c.drawString(50, h - 50, \"Generated Story\")\n",
        "\n",
        "    text = textwrap.wrap(story_text, 100)\n",
        "    y = h - 80\n",
        "    for line in text:\n",
        "        if y < 80:\n",
        "            c.showPage()\n",
        "            y = h - 80\n",
        "        c.drawString(50, y, line)\n",
        "        y -= 15\n",
        "\n",
        "    if images:\n",
        "        c.showPage()\n",
        "        c.setFont(\"Helvetica-Bold\", 16)\n",
        "        c.drawString(50, h - 50, \"Uploaded Images\")\n",
        "        x, y = 50, h - 150\n",
        "        for img in images:\n",
        "            img.thumbnail((200, 200))\n",
        "            c.drawImage(ImageReader(img), x, y, width=img.width, height=img.height)\n",
        "            x += 220\n",
        "            if x > w - 200:\n",
        "                x = 50\n",
        "                y -= 220\n",
        "    c.save()\n",
        "    buffer.seek(0)\n",
        "    return buffer\n",
        "\n",
        "#Audio generation\n",
        "def create_audio(story):\n",
        "    audio_bytes = io.BytesIO()\n",
        "    tts = gTTS(story)\n",
        "    tts.write_to_fp(audio_bytes)\n",
        "    audio_bytes.seek(0)\n",
        "    return audio_bytes\n",
        "\n",
        "\n",
        "#Processing part\n",
        "if st.button(\"Generate Story\") and uploaded_images:\n",
        "    pil_images = [Image.open(img) for img in uploaded_images]\n",
        "    with st.spinner(\"Generating captions...\"):\n",
        "        captions = get_captions(pil_images)\n",
        "        for i, cap in enumerate(captions):\n",
        "            st.write(f\"**Image {i+1}**: {cap}\")\n",
        "\n",
        "    with st.spinner(\"Generating story...\"):\n",
        "        story = generate_story(captions, tone, length_label)\n",
        "        st.success(\"Story generated!\")\n",
        "        st.write(story)\n",
        "\n",
        "    with st.spinner(\"Creating PDF...\"):\n",
        "        pdf_file = create_pdf(story, pil_images)\n",
        "        st.download_button(\"üìÑ Download Story as PDF\", data=pdf_file, file_name=\"story.pdf\", mime=\"application/pdf\")\n",
        "\n",
        "    with st.spinner(\"Creating Audio...\"):\n",
        "        audio = create_audio(story)\n",
        "        st.audio(audio)\n",
        "        st.download_button(\"üîä Download Story as MP3\", data=audio, file_name=\"story.mp3\", mime=\"audio/mpeg\")\n",
        "\n",
        "elif not uploaded_images:\n",
        "    st.warning(\"Upload at least one image to begin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au946lH4m3XT",
        "outputId": "5100f8ae-7f1e-45ee-aaa8-248f9950db3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app_streamlit_story.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()\n",
        "!pip install -q streamlit pyngrok transformers torch gtts reportlab Pillow\n",
        "\n",
        "!streamlit run app_streamlit_story.py --server.port 8501 &>/content/log.txt &\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"32p3bRt5N7Yn4CLlwyZJk5HIe7c_xsX6L2urkk97RwmDLkRM\")\n",
        "url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXPu8Fb4bKsA",
        "outputId": "8c0a4614-bdf7-4004-85a5-e0aea44e52ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://8af6-34-126-93-42.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}